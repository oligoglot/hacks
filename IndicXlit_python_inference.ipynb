{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oligoglot/hacks/blob/master/IndicXlit_python_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the python library, that is wrapper around IndicXlit model"
      ],
      "metadata": {
        "id": "LSHVk7J9jKxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing library\n",
        "# for thorough documentation: https://pypi.org/project/ai4bharat-transliteration/\n",
        "!pip install ai4bharat-transliteration"
      ],
      "metadata": {
        "id": "HMDCvP8uhNZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c128bb-4e76-4765-f4c4-bed237c34fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ai4bharat-transliteration\n",
            "  Downloading ai4bharat_transliteration-1.1.3-py3-none-any.whl (32 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mock\n",
            "  Downloading mock-5.0.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from ai4bharat-transliteration) (1.3.5)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from ai4bharat-transliteration) (1.1.4)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairseq\n",
            "  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydload\n",
            "  Downloading pydload-1.0.9-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ujson\n",
            "  Downloading ujson-5.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from ai4bharat-transliteration) (9.0.0)\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting urduhack\n",
            "  Downloading urduhack-1.1.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.5/105.5 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from ai4bharat-transliteration) (4.64.1)\n",
            "Collecting gevent\n",
            "  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq->ai4bharat-transliteration) (1.15.1)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq->ai4bharat-transliteration) (1.21.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq->ai4bharat-transliteration) (2022.6.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq->ai4bharat-transliteration) (1.13.1+cu116)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.4/240.4 KB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq->ai4bharat-transliteration) (0.13.1+cu116)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq->ai4bharat-transliteration) (0.29.33)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask->ai4bharat-transliteration) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask->ai4bharat-transliteration) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask->ai4bharat-transliteration) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask->ai4bharat-transliteration) (7.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.8/dist-packages (from flask-cors->ai4bharat-transliteration) (1.15.0)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 KB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gevent->ai4bharat-transliteration) (2.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from gevent->ai4bharat-transliteration) (57.4.0)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.1.1-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ai4bharat-transliteration) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ai4bharat-transliteration) (2022.7)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.8/dist-packages (from pydload->ai4bharat-transliteration) (3.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pydload->ai4bharat-transliteration) (2.25.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->ai4bharat-transliteration) (1.2.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX->ai4bharat-transliteration) (3.19.6)\n",
            "Collecting tf2crf\n",
            "  Downloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting tensorflow-datasets~=3.1\n",
            "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq->ai4bharat-transliteration) (5.10.2)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask->ai4bharat-transliteration) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (4.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (6.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (1.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (0.3.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (2.2.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (1.14.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (22.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pydload->ai4bharat-transliteration) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pydload->ai4bharat-transliteration) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pydload->ai4bharat-transliteration) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pydload->ai4bharat-transliteration) (4.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq->ai4bharat-transliteration) (2.21)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from progressbar2->pydload->ai4bharat-transliteration) (3.4.5)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (3.5.4)\n",
            "Requirement already satisfied: docutils<0.18 in /usr/local/lib/python3.8/dist-packages (from sphinx-rtd-theme->indic-nlp-library->ai4bharat-transliteration) (0.16)\n",
            "Collecting tensorflow-addons>=0.8.2\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from tf2crf->urduhack->ai4bharat-transliteration) (2.9.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (21.3)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.6.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.11.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (0.7.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (1.12)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (1.51.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (15.0.6.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.29.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (3.3.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons>=0.8.2->tf2crf->urduhack->ai4bharat-transliteration) (2.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq->ai4bharat-transliteration) (3.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (1.58.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (1.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (6.0.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (3.2.2)\n",
            "Building wheels for collected packages: sacremoses, antlr4-python3-runtime\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=474fab5775cdf14a1c38bfe6de1481da1853e710fff7a15a9f34ec16902c8040\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=31ad08ef935fd09de66a67256a127dea0d4b541fa1a55d8d97a29e8932e4432f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "Successfully built sacremoses antlr4-python3-runtime\n",
            "Installing collected packages: morfessor, bitarray, antlr4-python3-runtime, zope.interface, zope.event, ujson, tensorboardX, sacremoses, portalocker, omegaconf, mock, colorama, tensorflow-addons, sacrebleu, pydload, hydra-core, gevent, tensorflow-datasets, sphinx-rtd-theme, sphinx-argparse, flask-cors, fairseq, indic-nlp-library, tf2crf, urduhack, ai4bharat-transliteration\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.8.1\n",
            "    Uninstalling tensorflow-datasets-4.8.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.8.1\n",
            "Successfully installed ai4bharat-transliteration-1.1.3 antlr4-python3-runtime-4.8 bitarray-2.6.2 colorama-0.4.6 fairseq-0.12.2 flask-cors-3.0.10 gevent-22.10.2 hydra-core-1.0.7 indic-nlp-library-0.81 mock-5.0.1 morfessor-2.0.6 omegaconf-2.0.6 portalocker-2.7.0 pydload-1.0.9 sacrebleu-2.3.1 sacremoses-0.0.53 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.1.1 tensorboardX-2.5.1 tensorflow-addons-0.19.0 tensorflow-datasets-3.2.1 tf2crf-0.1.33 ujson-5.7.0 urduhack-1.1.1 zope.event-4.6 zope.interface-5.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the module for transliteration engine"
      ],
      "metadata": {
        "id": "Tp_6RHAJjBrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model support the following languages : [as, bn, brx, gom, gu, hi, kn, ks, mai, ml, mni, mr, ne, or, pa, sa, sd, si, ta, te, ur]\n",
        "# importing ai4bharat transliteration module\n",
        "from ai4bharat.transliteration import XlitEngine"
      ],
      "metadata": {
        "id": "hlqnZ8RrjI-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using word Transliteration"
      ],
      "metadata": {
        "id": "dnYV1YX-iy4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- beam_width increases beam search size, resulting in improved accuracy but increases time/compute. (Default: 4)\n",
        "- topk returns only specified number of top results. (Default: 4)\n",
        "- rescore returns the reranked suggestions after using a dictionary. (Default: True)"
      ],
      "metadata": {
        "id": "uklMFr9zjmh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### En-Indic conversion"
      ],
      "metadata": {
        "id": "4blljLKI1fy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# intializing the en-indic multilingual model and dictionaries (if rerank option is True)\n",
        "e = XlitEngine(\"hi\", beam_width=4, rescore=True, src_script_type = \"en\")\n",
        "\n",
        "# transliterate word\n",
        "out = e.translit_word(\"one\", topk=1)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "gLz7B4pxhPq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4ed296-97f9-45a8-d026-5f15109030c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MB100% (121.0 of 121.0) |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succefully Downloaded to: /usr/local/lib/python3.8/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/model.zip\n",
            "Models downloaded to: /usr/local/lib/python3.8/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0\n",
            "NOTE: When uninstalling this library, REMEMBER to delete the models manually\n",
            "Downloading language model probablitites dictionaries for rescoring module\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MB100% (812.0 of 812.0) |################| Elapsed Time: 0:00:09 Time:  0:00:09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succefully Downloaded to: /usr/local/lib/python3.8/dist-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/dicts.zip\n",
            "Initializing Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "Loading dicts into RAM: 100%|██████████| 1/1 [00:02<00:00,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hi': ['ओने']}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Indic-En conversion"
      ],
      "metadata": {
        "id": "LXv2pg2S1lMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# intializing the indic-en multilingual model and dictionaries (if rerank option is True)\n",
        "e = XlitEngine( beam_width=4, rescore=False, src_script_type = \"indic\")\n",
        "\n",
        "# transliterate Hindi word\n",
        "out = e.translit_word(\"भारत\", 'hi', topk=5)\n",
        "print(out)\n",
        "\n",
        "# transliterate Gujarati word\n",
        "out = e.translit_word(\"ગુજરાત\", 'gu', topk=5)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEsUEQOP1aHk",
        "outputId": "0e68efd6-2713-4324-91e1-bb901f4208a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MB100% (119.0 of 119.0) |################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succefully Downloaded to: /usr/local/lib/python3.8/dist-packages/ai4bharat/transliteration/transformer/models/indic2en/v1.0/model.zip\n",
            "Models downloaded to: /usr/local/lib/python3.8/dist-packages/ai4bharat/transliteration/transformer/models/indic2en/v1.0\n",
            "NOTE: When uninstalling this library, REMEMBER to delete the models manually\n",
            "Initializing Multilingual model for transliteration\n",
            "['bhaarat', 'bharat', 'bharath', 'bhart']\n",
            "['gujaraat', 'gujarat', 'goojarat', 'gujraat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word Transliteration without rescoring"
      ],
      "metadata": {
        "id": "DHfnnSY-i42Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### En-Indic conversion"
      ],
      "metadata": {
        "id": "XbdQL-Xd4CF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = XlitEngine(\"hi\", beam_width=10, rescore=False, src_script_type = \"en\")\n",
        "out = e.translit_word(\"one\", topk=5)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "Wlw5eJZWi1U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38d0987-9dc4-40c4-d47c-c670beea3a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Multilingual model for transliteration\n",
            "{'hi': ['ओने', 'ओन', 'ओनी', 'ओणे', 'ओना']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Indic-En conversion"
      ],
      "metadata": {
        "id": "C1a5Byux4AR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# intializing the indic-en multilingual model and dictionaries (if rerank option is True)\n",
        "e = XlitEngine( beam_width=10, rescore=False, src_script_type = \"indic\")\n",
        "\n",
        "# transliterate Hindi word\n",
        "out = e.translit_word(\"भारत\", 'hi', topk=5)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAr6kgre3594",
        "outputId": "f6cd25b4-6187-48a1-d931-f9413d98bc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Multilingual model for transliteration\n",
            "['bhaarat', 'bharat', 'bharath', 'bharata', 'bhaarut']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Sentence Transliteration"
      ],
      "metadata": {
        "id": "2CsQUh-9i37u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Only single top most prediction is returned for each word in sentence."
      ],
      "metadata": {
        "id": "5JFysasHkKHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### En-Indic conversion"
      ],
      "metadata": {
        "id": "QxCdp1Y34O58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = XlitEngine([\"te\", 'mr'], beam_width=10, src_script_type = \"en\")\n",
        "out = e.translit_sentence(\"102 VAnakkam ulagam\")\n",
        "print(out)"
      ],
      "metadata": {
        "id": "GCCpEKTQj2Yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe67e9b-6e50-4609-d8a0-7f125c9c671f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dicts into RAM: 100%|██████████| 2/2 [00:14<00:00,  7.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mr': '१०२ वणक्कम उलगम', 'te': '౧౦౨ వణక్కం ఉలగం'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Indic-En conversion"
      ],
      "metadata": {
        "id": "t7Zrj3lE4Pdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = XlitEngine( beam_width=10, src_script_type = \"indic\")\n",
        "out = e.translit_sentence(\"వణక్కం ఉలగం\", 'te')\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAhZCHqs4Fhn",
        "outputId": "4bc7bd07-b427-4b20-c54e-25c3de1b218a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dicts into RAM: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vanakkam ulagam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Multiple language Transliteration"
      ],
      "metadata": {
        "id": "SAbxWwFji7TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass list of languages for multile language transliteration\n",
        "e = XlitEngine([\"ta\", \"ml\"], beam_width=6, src_script_type = \"en\")\n",
        "# leave empty or use \"all\" to load all available languages\n",
        "# e = XlitEngine(\"all)\n",
        "\n",
        "out = e.translit_word(\"amma\", topk=3)\n",
        "print(out)\n",
        "\n",
        "out = e.translit_sentence(\"hello world\")\n",
        "print(out)\n",
        "\n",
        "## Specify language name to get only specific language result\n",
        "out = e.translit_word(\"amma\", topk=5)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "J0_CL02Lj284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545b76aa-f90c-4dfb-9302-17f1e57f84ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Multilingual model for transliteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dicts into RAM: 100%|██████████| 2/2 [01:11<00:00, 35.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ml': ['അമ്മ', 'അമ്മാ', 'ആമ്മ'], 'ta': ['அம்மா', 'ஆம்மா', 'அம்ம']}\n",
            "{'ml': 'ഹെല്ലോ വർൾഡ്', 'ta': 'ஹெல்லோ வர்ல்ட்'}\n",
            "{'ml': ['അമ്മ', 'അമ്മാ', 'ആമ്മ', 'എഎമ്എ', 'അംമ'], 'ta': ['அம்மா', 'ஆம்மா', 'அம்ம', 'அம்மை', 'அமா']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transliteration for all available languages"
      ],
      "metadata": {
        "id": "DypOGQxXi9SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading all the language dictionaries would require 8-10 gb of space in RAM\n",
        "e = XlitEngine(beam_width=10, src_script_type = \"en\")\n",
        "out = e.translit_sentence(\"Hello World\")\n",
        "print(out)"
      ],
      "metadata": {
        "id": "7NqUeCKKj3bY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}